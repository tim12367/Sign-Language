{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23e76e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cb5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.decomposition import PCA\n",
    "from keras import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da8445c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path for exported data, numpy arrays\n",
    "DATA_PATH = os.path.join(r\"/Users/krama/Desktop/Sign Language/Sign Language Dataset/Data\") \n",
    "\n",
    "subfolders = [ f.name for f in os.scandir(DATA_PATH) if f.is_dir() ]\n",
    "print(subfolders)\n",
    "\n",
    "# Actions that we try to detect\n",
    "actions = subfolders\n",
    "# Thirty videos worth of data\n",
    "no_sequences = 100\n",
    "\n",
    "\n",
    "# Videos are going to be 60 frames in length\n",
    "sequence_length = 60\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b951099",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258603b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences,labels=[],[]\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window=[]\n",
    "        for frame_num in range(sequence_length):\n",
    "            \n",
    "            res=np.load(os.path.join(DATA_PATH, action, str(sequence), str(frame_num) + \".npy\"))\n",
    "            pose=res[:33*4]#pose\n",
    "            hands=res[33*4:]\n",
    "            \n",
    "            pose=pose.reshape(-1,4)\n",
    "            hands=hands.reshape(-1,3)\n",
    "            \n",
    "            pose1=pose[:,0:3]-pose[0,0:3]\n",
    "            hand1=hands[:,:]-pose[0,0:3]\n",
    "            hand1[hands==0]=0\n",
    "            pose1=np.concatenate([np.expand_dims(pose1[0],axis=0),pose1[11:23]],axis=0).flatten()\n",
    "            all_pt=np.concatenate([pose1,hand1.flatten()],axis=0)\n",
    "            window.append(all_pt)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e7f98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(sequences).shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f346a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"/Users/krama/Desktop/Sign Language/Sign Language Dataset/Refined_New_X_100\",np.array(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff8ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r\"/Users/krama/Desktop/Sign Language/Sign Language Dataset/Refined_New_Y_100\",np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414a3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab\n",
    "# sequences = np.load('/content/drive/MyDrive/AI Python/Dataset/Refined_New_X.npy')\n",
    "# labels = np.load('/content/drive/MyDrive/AI Python/Dataset/Refined_New_Y.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5831775",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b024b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67680a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "252bda65",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8511793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38729a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(GRU(512, return_sequences=True, activation='elu', input_shape=(60,165)))\n",
    "model.add(GRU(1024, return_sequences=True, activation='elu'))\n",
    "model.add(GRU(512, return_sequences=False, activation='elu'))\n",
    "model.add(Dense(512, activation='elu'))\n",
    "model.add(Dense(256, activation='elu'))\n",
    "model.add(Dense(np.array(actions).shape[0], activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53b11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['categorical_accuracy'])\n",
    "import keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "#checkpoint = keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/AI Python/Dataset/Dropout.h5', monitor='val_categorical_accuracy', mode=\"max\", save_best_only=True, verbose=1)\n",
    "earlystopping = keras.callbacks.EarlyStopping(monitor='val_loss', mode=\"auto\", patience=3, verbose=1)\n",
    "rlr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, mode='auto')\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train,validation_split = 0.1,\n",
    "              epochs=30,\n",
    "              batch_size = 32,\n",
    "              callbacks=[rlr,earlystopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'test_loss={test_loss}')\n",
    "print(f'test_accuracy={test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a24b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('action.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fe5db0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f0f964",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77474ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
